{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKXY9HhEvV9tgSVp8hwiha",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZaraGiraffe/ZaraNLP/blob/main/text_generation_by_characters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_Xr2xRxtnE_e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import string\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the data file"
      ],
      "metadata": {
        "id": "PjbNsNGfT3CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "EAbkBguDnYcq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = open(path_to_file, \"r\").read()\n",
        "len(all_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLKsojrOp-4Q",
        "outputId": "91aee1df-0aba-4b02-f556-c1f1e90bbacf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_length = len(set(all_text))\n",
        "vocab_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIScSoR2s0i5",
        "outputId": "71f8e396-471e-4350-c404-9527be8bde10"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My first Try to predict next character in tensorflow"
      ],
      "metadata": {
        "id": "nnCz6wBxTrvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creater helper transforms"
      ],
      "metadata": {
        "id": "3N7X8OURkX7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = layers.StringLookup(vocabulary=list(set(all_text)))"
      ],
      "metadata": {
        "id": "xKPckgZ6txQ5"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exm_ids = ids_from_chars(tf.strings.unicode_split([\"avc\", \"vvc\"], input_encoding=\"UTF-8\"))\n",
        "exm_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irPlcrNcvLAz",
        "outputId": "b4f3ea39-d167-46b2-e9c2-bad9cd3f09fe"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[17, 19, 12],\n",
              " [19, 19, 12]]>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "metadata": {
        "id": "B6auLW6fvrnx"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exm_chars = chars_from_ids(exm_ids)\n",
        "exm_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci0yvSY-wM_Q",
        "outputId": "51720332-a849-4892-c59a-bfac648f5513"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'v', b'c'],\n",
              " [b'v', b'v', b'c']]>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(all_text, \"UTF-8\"))\n",
        "all_ids.shape"
      ],
      "metadata": {
        "id": "A_s3u6CNw2go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d05648f-c169-4498-bf7d-1a222d948a00"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1115394])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "2_DnVcVXbAFd"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the dataset"
      ],
      "metadata": {
        "id": "cljaQ5ZHkUCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "xclEPM7aX2xh"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = next(iter(ids_dataset.batch(20).take(1)))\n",
        "text_from_ids(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMRbOEWhYdKy",
        "outputId": "1a5978ed-b24b-4fd4-d3d3-d7f932d34cda"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'First Citizen:\\nBefor'>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = next(iter(ids_dataset.take(1)))\n",
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EyWcPWpmlyC",
        "outputId": "ffbbf62d-96df-40a8-b133-ab3491db4262"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=50>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(Id):\n",
        "    return tf.one_hot(Id, vocab_length)"
      ],
      "metadata": {
        "id": "TJQoVJ_ik-LN"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_ohe_dataset = ids_dataset.map(one_hot_encoding)"
      ],
      "metadata": {
        "id": "sjZrLHo7ltv6"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100 + 1\n",
        "ids_sequences = ids_ohe_dataset.batch(seq_length)"
      ],
      "metadata": {
        "id": "SPGDAseEdWmx"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_seq = sequence[:-1]\n",
        "    output_seq = sequence[1:]\n",
        "    return input_seq, output_seq"
      ],
      "metadata": {
        "id": "WXQcJv31hPfL"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ids_sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "diittPN8hxyi"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create batches for dataset"
      ],
      "metadata": {
        "id": "DwXljxBhiX8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "buffer_size = 10000\n",
        "batched_dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "TXZUjLt3iNtj"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the model"
      ],
      "metadata": {
        "id": "mTHkW40YocyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ZaraModelFirstLstmTry(tf.keras.Model):\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super().__init__()\n",
        "        self.lstm = layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.dense = layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, X, training=False):\n",
        "        out = self.lstm(X, training=training)\n",
        "        y = self.dense(out, training=training)\n",
        "        return y"
      ],
      "metadata": {
        "id": "IF_wRdRDoDwb"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the model"
      ],
      "metadata": {
        "id": "sa4u4YCR77GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size=128\n",
        "model = ZaraModelFirstLstmTry(hidden_size, vocab_length)"
      ],
      "metadata": {
        "id": "m7m5AczG6B1U"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, Y in batched_dataset.take(1):\n",
        "    print(model(X).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxF3fj6_8Ke8",
        "outputId": "dfafbcaa-b1c7-404d-b7b4-0772c35a54ab"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NYVWK5wC8rA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}